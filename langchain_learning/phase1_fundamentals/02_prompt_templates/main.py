# !/usr/bin/env python
# -*- coding: utf-8 -*-
""""""
# ----------------------------------------------------------------------------------------------------------------------
from os import getenv
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate

load_dotenv()

api_key = getenv('DEEPSEEK_API_KEY')

model = init_chat_model(
    model='deepseek-chat',
    api_key=api_key,
    max_tokens=500,
)


# 1.ä¸ºä»€ä¹ˆç”¨æç¤ºè¯æ¨¡æ¿ï¼ˆå¯¹æ¯”å­—ç¬¦ä¸²æ‹¼æ¥ï¼‰
def example_1_why_template():
    # å­—ç¬¦ä¸²æ‹¼æ¥
    topic = 'AIåº”ç”¨å¼€å‘'
    difficulty = 'medium'
    prompt_str = f'ä½ æ˜¯ä¸€ä¸ª{difficulty}çº§åˆ«çš„ç¼–ç¨‹å¯¼å¸ˆã€‚è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Š{topic}ã€‚'
    response_str = model.invoke(prompt_str)
    print(response_str.content)

    # ç®€å•æç¤ºè¯æ¨¡æ¿ PromptTemplate
    template = PromptTemplate.from_template(
        'ä½ æ˜¯ä¸€ä¸ª{difficulty}çº§åˆ«çš„ç¼–ç¨‹å¯¼å¸ˆï¼Œè¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Š{topic}ã€‚'
    )
    prompt = template.format(
        difficulty=difficulty,
        topic=topic,
    )
    response_prompt = model.invoke(prompt)
    print(response_prompt.content)
    '''ğŸ’¡ ä¼˜åŠ¿ï¼š
    1. å¯å¤ç”¨ - åŒä¸€ä¸ªæ¨¡æ¿å¯ä»¥ç”¨äºä¸åŒçš„è¾“å…¥
    2. å¯ç»´æŠ¤ - æ¨¡æ¿å’Œæ•°æ®åˆ†ç¦»ï¼Œæ˜“äºä¿®æ”¹
    3. ç±»å‹å®‰å…¨ - è‡ªåŠ¨éªŒè¯å˜é‡
    4. å¯æµ‹è¯• - æ›´å®¹æ˜“ç¼–å†™æµ‹è¯•ç”¨ä¾‹'''


# 2ï¼šPromptTemplate åŸºç¡€ç”¨æ³•
def example_2_prompt_template_basics():
    # PromptTemplateç”¨äºç®€å•åœºæ™¯

    # 1.from_templateï¼ˆæœ€æ¨èï¼‰

    template_first = PromptTemplate.from_template(
        'å°†ä¸‹åˆ—æ–‡æœ¬ç¿»è¯‘æˆ{language}ï¼š\n{text}'
    )
    prompt_first = template_first.format(
        language='éŸ©è¯­',
        text='ä½ å¥½ï¼Œæˆ‘æ˜¯AIåº”ç”¨å·¥ç¨‹å¸ˆã€‚'
    )
    print(prompt_first)

    res_first = model.invoke(prompt_first)
    print(res_first.content)

    # 2.æ˜¾ç¤ºæŒ‡å®šå˜é‡ï¼ˆè¯­æ³•æ›´ä¸¥æ ¼ï¼‰
    template_second = PromptTemplate(
        input_variables=['product', 'feature'],
        template='ä¸º{product}äº§å“ç¼–å†™ä¸€æ®µå¹¿å‘Šæ ‡è¯­ï¼Œä»¥{feature}ä¸ºæ ¸å¿ƒ,ä»¥{language}æ˜¾ç¤ºã€‚',
    )
    prompt_second = template_second.format(
        product='æ™ºèƒ½æ‰‹è¡¨',
        feature='æŒæ§æ—¶é—´',
        language='ä¸­æ–‡ç¹ä½“'
    )
    print(prompt_second)

    res_second = model.invoke(prompt_second)
    print(res_second.content)
    print(res_second)

    # 3.invokeç›´æ¥ç”Ÿæˆï¼ˆæ›´æ–¹ä¾¿ï¼‰
    template_third = PromptTemplate.from_template(
        "ä¸º{season}å†™ä¸€é¦–{style}è¯—ï¼Œå­—æ•°{count}"
    )

    # invoke ç›´æ¥è¿”å›æ ¼å¼åŒ–åçš„å€¼
    prompt_third = template_third.invoke({
        'season': 'å†¬å¤©',
        'style': 'ç°ä»£',
        'count': '100',
    })
    print(prompt_third)

    res_third = model.invoke(prompt_third)
    print(res_third.content)


# 3.ChatPromptTemplate èŠå¤©æ¶ˆæ¯æ¨¡æ¿
def example_3_chatprompttemplate():
    # ä½¿ç”¨å…ƒç»„æ ¼å¼ï¼ˆæœ€ç®€å•ï¼Œæ¨èï¼‰
    template = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œæ“…é•¿{expertise}ã€‚"),
        ("user", "è¯·ç»™æˆ‘{task}"),
    ])

    messages = template.format_messages(
        role='AIæ•™æˆ',
        expertise='å¤§æ¨¡å‹å¼€å‘',
        task='è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ',
    )
    print(messages)

    res_chat = model.invoke(messages)
    print(res_chat.content)


# â€œæ›´ç»†ç²’åº¦çš„æ§åˆ¶â€æŒ‡çš„æ˜¯èƒ½å¤Ÿæ·±å…¥åˆ°æ¡†æ¶çš„å„ä¸ªç»„ä»¶å’Œæµç¨‹ä¸­ï¼Œè¿›è¡Œå®šåˆ¶åŒ–è°ƒæ•´å’Œå¹²é¢„ã€‚
def main():
    try:
        # example_1_why_template()
        # example_2_prompt_template_basics()
        example_3_chatprompttemplate()

    except Exception as e:
        print(e)


if __name__ == '__main__':
    main()
